{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& batch\\_first=True, 那么shape就是(N, L, H_{in}) \\\\\n",
    "& N = batch\\_size \\\\\n",
    "& L = sequence length \\\\\n",
    "& D = 2\\ if\\  bidirectional=True\\ otherwise\\ 1 \\\\\n",
    "& H_{in} = input_size \\\\\n",
    "& H_{out} = hidden_size \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size=100, hidden_size=20, num_layers=1\n",
    "rnn = nn.RNN(input_size=100, hidden_size=20, num_layers=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入3个样本序列(batch=3), 序列长为10(seq_len=10), 每个特征100维度(feature_len=100)\n",
    "x = torch.randn(3, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传入RNN处理, 另外传入h_0, shape是< 层数 * bidirectional, batch, hidden_len=20 >\n",
    "\n",
    "# out shape是 batch_size, seqence_len, bidirectional * hidden_size\n",
    "out, h = rnn(x, torch.zeros(2, 3, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出是每一个时刻在空间上最后一层的输出[batch, seq, hidden_size]\n",
    "\n",
    "ht是最后一个时刻上所有层的记忆单元 [batch, num_layers, hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out shape is:  torch.Size([3, 10, 20])\n",
      "h shape is:  torch.Size([2, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "# 输出返回的out和最终的隐藏记忆单元的shape\n",
    "print('out shape is: ', out.shape)  # torch.Size([3, 10, 20])\n",
    "print('h shape is: ', h.shape)  # torch.Size([1, 3, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=100, hidden_size=20, num_layers=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入shape [batch_size, seq_len, input_size] batch_first=True\n",
    "x = torch.rand(3, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化两个状态，隐状态ht和内部状态ct, shape = [双向bidirectional * num_layers, batch_size, hidden_size];\n",
    "# – input (seq_len, batch, input_size)\n",
    "# – h_0 (num_layers * num_directions, batch, hidden_size)\n",
    "# – c_0 (num_layers * num_directions, batch, hidden_size)\n",
    "h0 = torch.rand(2, 3, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = torch.rand(2, 3, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(x, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 20])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 20])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
